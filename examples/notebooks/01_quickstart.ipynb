{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# pyhdb-rs Quick Start Guide\n",
    "\n",
    "High-performance Python driver for SAP HANA with native Arrow support.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Zero-copy Arrow transfer** via PyCapsule interface\n",
    "- **Native Polars/pandas integration** without serialization overhead\n",
    "- **2x+ faster** than hdbcli for bulk reads\n",
    "- **DB-API 2.0 compliant** (PEP 249)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```bash\n",
    "uv pip install pyhdb_rs polars pyarrow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyhdb_rs import connect\n",
    "\n",
    "# Connection URL (set via environment variable for security)\n",
    "HANA_URL = os.environ.get(\"HANA_TEST_URI\", \"hdbsql://user:password@host:39017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-connection",
   "metadata": {},
   "source": [
    "## Basic Connection\n",
    "\n",
    "pyhdb-rs follows the DB-API 2.0 standard, so it works like any Python database driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connect-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context manager ensures proper cleanup\n",
    "with connect(HANA_URL) as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT 'Hello from HANA!' AS greeting\")\n",
    "    row = cursor.fetchone()\n",
    "    print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polars-section",
   "metadata": {},
   "source": [
    "## Direct Polars Integration\n",
    "\n",
    "The `execute_polars()` method returns a Polars DataFrame with **zero-copy** data transfer.\n",
    "Data flows directly from HANA → Rust → Arrow → Polars without Python object creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polars-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(HANA_URL) as conn, conn.cursor() as cursor:\n",
    "    # Returns pl.DataFrame directly - no intermediate conversion!\n",
    "    df = cursor.execute_polars(\"\"\"\n",
    "            SELECT \n",
    "                PRODUCT_ID,\n",
    "                PRODUCT_NAME,\n",
    "                CATEGORY,\n",
    "                PRICE,\n",
    "                STOCK_QUANTITY\n",
    "            FROM PRODUCTS\n",
    "            WHERE PRICE > 100\n",
    "        \"\"\")\n",
    "\n",
    "    print(f\"Loaded {len(df):,} rows\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arrow-section",
   "metadata": {},
   "source": [
    "## Arrow Integration\n",
    "\n",
    "For maximum flexibility, use `execute_arrow()` to get a PyArrow Table.\n",
    "This can be converted to pandas, Polars, DuckDB, or any Arrow-compatible tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arrow-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(HANA_URL) as conn, conn.cursor() as cursor:\n",
    "    # Get PyArrow Table\n",
    "    arrow_table = cursor.execute_arrow(\"\"\"\n",
    "            SELECT * FROM SALES_DATA\n",
    "            WHERE SALE_DATE >= '2024-01-01'\n",
    "        \"\"\")\n",
    "\n",
    "    print(f\"Schema: {arrow_table.schema}\")\n",
    "    print(f\"Rows: {arrow_table.num_rows:,}\")\n",
    "    print(f\"Memory: {arrow_table.nbytes / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "        # Convert to pandas if needed\n",
    "        # pandas_df = arrow_table.to_pandas()\n",
    "\n",
    "        # Or to Polars\n",
    "        # polars_df = pl.from_arrow(arrow_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arrow-pycapsule-section",
   "metadata": {},
   "source": [
    "## Arrow PyCapsule Interface\n",
    "\n",
    "The `RecordBatchReader` implements the Arrow PyCapsule Interface (`__arrow_c_stream__` protocol),\n",
    "enabling zero-copy data transfer to any Arrow-compatible library.\n",
    "\n",
    "This protocol is automatically used by Polars, PyArrow, pandas, and other libraries when you pass\n",
    "the reader directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arrow-pycapsule-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "with connect(HANA_URL) as conn, conn.cursor() as cursor:\n",
    "    # execute_arrow() returns a RecordBatchReader\n",
    "    reader = cursor.execute_arrow(\"SELECT * FROM SALES\")\n",
    "\n",
    "    # PyArrow uses __arrow_c_stream__ protocol automatically\n",
    "    pa_reader = pa.RecordBatchReader.from_stream(reader)\n",
    "    table = pa_reader.read_all()\n",
    "\n",
    "    print(f\"Loaded {table.num_rows:,} rows via PyCapsule interface\")\n",
    "\n",
    "        # Note: The reader is consumed after use (single-use pattern)\n",
    "        # You cannot call read_all() again on the same reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arrow-pycapsule-note",
   "metadata": {},
   "source": [
    "**Important:** The `__arrow_c_stream__` method consumes the reader. After calling,\n",
    "the reader cannot be used again. This is a deliberate design choice to ensure\n",
    "memory safety in the Arrow C Data Interface.\n",
    "\n",
    "Most libraries (Polars, PyArrow) handle this automatically when you pass the reader to them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parameters-section",
   "metadata": {},
   "source": [
    "## Parameterized Queries\n",
    "\n",
    "Always use parameters for user input to prevent SQL injection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parameters-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(HANA_URL) as conn, conn.cursor() as cursor:\n",
    "    # Positional parameters\n",
    "    df = cursor.execute_polars(\n",
    "        \"SELECT * FROM ORDERS WHERE STATUS = ? AND TOTAL > ?\", [\"PENDING\", 1000.0]\n",
    "    )\n",
    "    print(f\"Pending orders > $1000: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch-insert-section",
   "metadata": {},
   "source": [
    "## Batch Insert\n",
    "\n",
    "Use `executemany()` for efficient bulk inserts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-insert-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data to insert\n",
    "products = [\n",
    "    (\"PROD001\", \"Widget A\", 29.99),\n",
    "    (\"PROD002\", \"Widget B\", 39.99),\n",
    "    (\"PROD003\", \"Widget C\", 49.99),\n",
    "]\n",
    "\n",
    "with connect(HANA_URL) as conn, conn.cursor() as cursor:\n",
    "    cursor.executemany(\"INSERT INTO PRODUCTS (ID, NAME, PRICE) VALUES (?, ?, ?)\", products)\n",
    "    conn.commit()\n",
    "    print(f\"Inserted {len(products)} products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transactions-section",
   "metadata": {},
   "source": [
    "## Transaction Control\n",
    "\n",
    "Transactions are controlled via `commit()` and `rollback()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transaction-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(HANA_URL) as conn:\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"UPDATE ACCOUNTS SET BALANCE = BALANCE - 100 WHERE ID = 1\")\n",
    "            cursor.execute(\"UPDATE ACCOUNTS SET BALANCE = BALANCE + 100 WHERE ID = 2\")\n",
    "            conn.commit()  # Both updates succeed\n",
    "            print(\"Transfer completed\")\n",
    "    except Exception as e:\n",
    "        conn.rollback()  # Undo all changes\n",
    "        print(f\"Transfer failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **[02_polars_analytics.ipynb](./02_polars_analytics.ipynb)** - Advanced Polars analytics\n",
    "- **[03_streaming_large_data.ipynb](./03_streaming_large_data.ipynb)** - Processing large datasets\n",
    "- **[04_performance_comparison.ipynb](./04_performance_comparison.ipynb)** - Benchmarks vs hdbcli"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
