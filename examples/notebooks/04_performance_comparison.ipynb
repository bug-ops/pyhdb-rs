{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Performance Comparison: pyhdb_rs vs hdbcli\n",
    "\n",
    "This notebook benchmarks pyhdb_rs against SAP's official hdbcli driver\n",
    "to demonstrate the performance advantages of Rust bindings with Arrow.\n",
    "\n",
    "## Architecture Comparison\n",
    "\n",
    "| Feature | hdbcli | pyhdb_rs |\n",
    "|---------|--------|----------|\n",
    "| Protocol implementation | C/Python | Rust |\n",
    "| Data transfer | Row-by-row Python objects | Zero-copy Arrow buffers |\n",
    "| Memory overhead | High (Python object per cell) | Low (columnar Arrow) |\n",
    "| GIL impact | Held during fetch | Released during fetch |\n",
    "| Polars integration | via pandas (copy) | Direct Arrow (zero-copy) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import tracemalloc\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# pyhdb_rs (Rust-based)\n",
    "from pyhdb_rs import connect as pyhdb_connect\n",
    "\n",
    "# hdbcli (SAP official)\n",
    "try:\n",
    "    from hdbcli import dbapi as hdbcli\n",
    "\n",
    "    HAS_HDBCLI = True\n",
    "except ImportError:\n",
    "    HAS_HDBCLI = False\n",
    "    print(\"hdbcli not installed - comparison will be skipped\")\n",
    "\n",
    "HANA_URL = os.environ.get(\"HANA_TEST_URI\")\n",
    "\n",
    "\n",
    "# Parse URL for hdbcli (which uses separate parameters)\n",
    "def parse_hana_url(url: str) -> dict:\n",
    "    from urllib.parse import urlparse\n",
    "\n",
    "    parsed = urlparse(url)\n",
    "    return {\n",
    "        \"address\": parsed.hostname,\n",
    "        \"port\": parsed.port or 39017,\n",
    "        \"user\": parsed.username,\n",
    "        \"password\": parsed.password,\n",
    "    }\n",
    "\n",
    "\n",
    "HANA_PARAMS = parse_hana_url(HANA_URL) if HANA_URL else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def measure_performance():\n",
    "    \"\"\"\n",
    "    Context manager to measure time and memory.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    tracemalloc.start()\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    result = {\"rows\": 0}\n",
    "    yield result\n",
    "\n",
    "    elapsed = time.perf_counter() - start_time\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    result[\"elapsed_sec\"] = elapsed\n",
    "    result[\"peak_memory_mb\"] = peak / 1024 / 1024\n",
    "    result[\"rows_per_sec\"] = result[\"rows\"] / elapsed if elapsed > 0 else 0\n",
    "\n",
    "\n",
    "def format_results(name: str, result: dict) -> str:\n",
    "    return (\n",
    "        f\"{name}:\\n\"\n",
    "        f\"  Rows: {result['rows']:,}\\n\"\n",
    "        f\"  Time: {result['elapsed_sec']:.3f}s\\n\"\n",
    "        f\"  Throughput: {result['rows_per_sec']:,.0f} rows/sec\\n\"\n",
    "        f\"  Peak Memory: {result['peak_memory_mb']:.1f} MB\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-1",
   "metadata": {},
   "source": [
    "## Benchmark 1: Fetch to DataFrame\n",
    "\n",
    "Compare fetching query results to a DataFrame (pandas for hdbcli, Polars for pyhdb_rs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"",
    "    SELECT ",
    "        ID,",
    "        NAME,",
    "        CATEGORY,",
    "        PRICE,",
    "        QUANTITY,",
    "        CREATED_AT",
    "    FROM BENCHMARK_TABLE",
    "    WHERE ID <= 1000000",
    "\"\"\"",
    "",
    "# pyhdb_rs benchmark",
    "with measure_performance() as pyhdb_result, pyhdb_connect(HANA_URL) as conn:",
    "    with conn.cursor() as cursor:",
    "        df = pl.from_arrow(cursor.execute_arrow(QUERY))",
    "        pyhdb_result[\"rows\"] = len(df)",
    "",
    "print(format_results(\"pyhdb_rs (Polars)\", pyhdb_result))",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-1-hdbcli",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_HDBCLI:\n",
    "    # hdbcli benchmark\n",
    "    with measure_performance() as hdbcli_result:\n",
    "        conn = hdbcli.connect(**HANA_PARAMS)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(QUERY)\n",
    "\n",
    "        # Fetch to pandas (hdbcli native way)\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        rows = cursor.fetchall()\n",
    "        df = pd.DataFrame(rows, columns=columns)\n",
    "        hdbcli_result[\"rows\"] = len(df)\n",
    "\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    print(format_results(\"hdbcli (pandas)\", hdbcli_result))\n",
    "\n",
    "    # Calculate speedup\n",
    "    speedup = hdbcli_result[\"elapsed_sec\"] / pyhdb_result[\"elapsed_sec\"]\n",
    "    memory_reduction = hdbcli_result[\"peak_memory_mb\"] / pyhdb_result[\"peak_memory_mb\"]\n",
    "\n",
    "    print(f\"\\n=== pyhdb_rs is {speedup:.1f}x faster ===\")\n",
    "    print(f\"=== pyhdb_rs uses {memory_reduction:.1f}x less memory ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-2",
   "metadata": {},
   "source": [
    "## Benchmark 2: Large Dataset Streaming\n",
    "\n",
    "Compare streaming large datasets that don't fit in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_QUERY = \"SELECT * FROM LARGE_TABLE\"  # 10M+ rows\n",
    "\n",
    "# pyhdb_rs streaming\n",
    "with measure_performance() as pyhdb_stream, pyhdb_connect(HANA_URL) as conn:\n",
    "    with conn.cursor() as cursor:\n",
    "        reader = cursor.execute_arrow_batches(LARGE_QUERY, batch_size=65536)\n",
    "\n",
    "        total = 0\n",
    "        for batch in reader:\n",
    "            # Simulate processing\n",
    "            total += batch.num_rows\n",
    "\n",
    "        pyhdb_stream[\"rows\"] = total\n",
    "\n",
    "print(format_results(\"pyhdb_rs streaming\", pyhdb_stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-2-hdbcli",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_HDBCLI:\n",
    "    # hdbcli fetchmany (chunked)\n",
    "    with measure_performance() as hdbcli_stream:\n",
    "        conn = hdbcli.connect(**HANA_PARAMS)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(LARGE_QUERY)\n",
    "\n",
    "        total = 0\n",
    "        while True:\n",
    "            rows = cursor.fetchmany(65536)\n",
    "            if not rows:\n",
    "                break\n",
    "            total += len(rows)\n",
    "\n",
    "        hdbcli_stream[\"rows\"] = total\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    print(format_results(\"hdbcli fetchmany\", hdbcli_stream))\n",
    "\n",
    "    speedup = hdbcli_stream[\"elapsed_sec\"] / pyhdb_stream[\"elapsed_sec\"]\n",
    "    print(f\"\\n=== pyhdb_rs streaming is {speedup:.1f}x faster ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-3",
   "metadata": {},
   "source": [
    "## Benchmark 3: Type-Heavy Workload\n",
    "\n",
    "Compare handling of complex types (DECIMAL, TIMESTAMP, LOBs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-3-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "DECIMAL_QUERY = \"\"\"",
    "    SELECT ",
    "        TRANSACTION_ID,",
    "        AMOUNT,",
    "        TAX,",
    "        DISCOUNT,",
    "        TOTAL,",
    "        EXCHANGE_RATE,",
    "        CREATED_AT,",
    "        UPDATED_AT",
    "    FROM FINANCIAL_TRANSACTIONS",
    "    WHERE CREATED_AT >= '2024-01-01'",
    "\"\"\"",
    "",
    "# pyhdb_rs with optimized decimal handling",
    "with measure_performance() as pyhdb_decimal, pyhdb_connect(HANA_URL) as conn:",
    "    with conn.cursor() as cursor:",
    "        df = pl.from_arrow(cursor.execute_arrow(DECIMAL_QUERY))",
    "        pyhdb_decimal[\"rows\"] = len(df)",
    "",
    "print(format_results(\"pyhdb_rs (DECIMAL optimized)\", pyhdb_decimal))",
    "print(f\"\\nSchema: {df.schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-4",
   "metadata": {},
   "source": [
    "## Benchmark 4: Concurrent Connections\n",
    "\n",
    "Compare performance under concurrent load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-4-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed",
    "",
    "CONCURRENT_QUERY = \"SELECT * FROM ORDERS WHERE ORDER_ID <= 10000\"",
    "NUM_THREADS = 8",
    "ITERATIONS = 10",
    "",
    "",
    "def pyhdb_worker(iteration: int) -> int:",
    "    with pyhdb_connect(HANA_URL) as conn, conn.cursor() as cursor:",
    "        df = pl.from_arrow(cursor.execute_arrow(CONCURRENT_QUERY))",
    "        return len(df)",
    "",
    "",
    "# pyhdb_rs concurrent benchmark",
    "with measure_performance() as pyhdb_concurrent:",
    "    with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:",
    "        futures = [executor.submit(pyhdb_worker, i) for i in range(ITERATIONS)]",
    "        total = sum(f.result() for f in as_completed(futures))",
    "    pyhdb_concurrent[\"rows\"] = total",
    "",
    "print(f\"Concurrent test: {NUM_THREADS} threads, {ITERATIONS} iterations\")",
    "print(format_results(\"pyhdb_rs concurrent\", pyhdb_concurrent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Performance Summary\n",
    "\n",
    "### Why pyhdb_rs is Faster\n",
    "\n",
    "1. **Zero-copy Arrow transfer**\n",
    "   - Data stays in Arrow format from Rust to Polars\n",
    "   - No Python object creation per cell\n",
    "   - No serialization/deserialization overhead\n",
    "\n",
    "2. **Rust protocol implementation**\n",
    "   - HANA protocol parsing in native code\n",
    "   - No GIL contention during network I/O\n",
    "   - SIMD-optimized data processing\n",
    "\n",
    "3. **Columnar memory layout**\n",
    "   - Arrow's columnar format is cache-friendly\n",
    "   - Better memory locality for analytics\n",
    "   - Efficient compression and encoding\n",
    "\n",
    "4. **Optimized type conversions**\n",
    "   - Direct BigInt arithmetic for DECIMAL (no string parsing)\n",
    "   - Thread-local Python type caches\n",
    "   - Builder reuse at batch boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary = pl.DataFrame(\n",
    "    {\n",
    "        \"Benchmark\": [\n",
    "            \"DataFrame fetch (1M rows)\",\n",
    "            \"Streaming (10M rows)\",\n",
    "            \"DECIMAL processing\",\n",
    "            \"Concurrent (8 threads)\",\n",
    "        ],\n",
    "        \"pyhdb_rs (sec)\": [\n",
    "            pyhdb_result.get(\"elapsed_sec\", 0),\n",
    "            pyhdb_stream.get(\"elapsed_sec\", 0),\n",
    "            pyhdb_decimal.get(\"elapsed_sec\", 0),\n",
    "            pyhdb_concurrent.get(\"elapsed_sec\", 0),\n",
    "        ],\n",
    "        \"pyhdb_rs Memory (MB)\": [\n",
    "            pyhdb_result.get(\"peak_memory_mb\", 0),\n",
    "            pyhdb_stream.get(\"peak_memory_mb\", 0),\n",
    "            pyhdb_decimal.get(\"peak_memory_mb\", 0),\n",
    "            pyhdb_concurrent.get(\"peak_memory_mb\", 0),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"=== Performance Summary ===\")\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}