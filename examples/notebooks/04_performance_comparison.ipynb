{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Performance Comparison: pyhdb_rs vs hdbcli\n",
    "\n",
    "This notebook benchmarks pyhdb_rs against SAP's official hdbcli driver\n",
    "to demonstrate the performance advantages of Rust bindings with Arrow.\n",
    "\n",
    "## Architecture Comparison\n",
    "\n",
    "| Feature | hdbcli | pyhdb_rs |\n",
    "|---------|--------|----------|\n",
    "| Protocol implementation | C++ native library¹ | Rust |\n",
    "| Data format | Python tuples | Arrow columnar |\n",
    "| Memory overhead | High (object per cell) | Low (columnar arrays) |\n",
    "| Polars integration | Via pandas (copy) | Native Arrow (zero-copy) |\n",
    "\n",
    "¹ Built on the same C++ library used by ODBC and ADO.NET ([source](https://community.sap.com/t5/technology-blogs-by-sap/sap-hana-2-0-sps02-new-feature-updated-python-driver/ba-p/13347969))\n",
    "\n",
    "## hdbcli Connection Parameters\n",
    "\n",
    "This notebook uses SAP HANA's official Python driver **hdbcli**.\n",
    "\n",
    "**Official Documentation**:\n",
    "- [hdbcli on PyPI](https://pypi.org/project/hdbcli/) (version 2.27.23+)\n",
    "- [SAP HANA Client Interface Programming Reference](https://help.sap.com/docs/SAP_HANA_CLIENT)\n",
    "- [Connection Parameters Reference](https://help.sap.com/viewer/0eec0d68141541d1b07893a39944924e/2.0.02/en-US/ee592e89dcce4480a99571a4ae7a702f.html)\n",
    "\n",
    "**Connection Method**: `hdbcli.dbapi.connect(address, port, user, password, ...)`\n",
    "\n",
    "Basic parameters: `address`, `port`, `user`, `password`\n",
    "\n",
    "Additional parameters: `encrypt`, `sslValidateCertificate`, `databaseName`, `autocommit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import tracemalloc\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# pyhdb_rs (Rust-based)\n",
    "from pyhdb_rs import connect as pyhdb_connect\n",
    "\n",
    "# hdbcli (SAP official)\n",
    "try:\n",
    "    from hdbcli import dbapi as hdbcli\n",
    "\n",
    "    HAS_HDBCLI = True\n",
    "except ImportError:\n",
    "    HAS_HDBCLI = False\n",
    "    print(\"hdbcli not installed - comparison will be skipped\")\n",
    "\n",
    "HANA_URL = os.environ.get(\"HANA_TEST_URI\")\n",
    "\n",
    "\n",
    "# Parse URL for hdbcli (which uses separate parameters)\n",
    "def parse_hana_url(url: str) -> dict:\n",
    "    \"\"\"Parse HANA connection URL to hdbcli parameters.\n",
    "\n",
    "    Default port 30015 assumes single-tenant HANA database (instance 00).\n",
    "\n",
    "    SAP HANA port convention (3NNMM):\n",
    "    - NN: Instance number (00-99)\n",
    "    - MM: Service type (13=tenant, 15=single-tenant)\n",
    "\n",
    "    Common ports:\n",
    "    - 443: HANA Cloud (encryption required)\n",
    "    - 30013: Tenant DB, instance 00\n",
    "    - 30015: Single-tenant DB, instance 00  (DEFAULT)\n",
    "    - 39013: Tenant DB, instance 90\n",
    "\n",
    "    References:\n",
    "        https://pypi.org/project/hdbcli/\n",
    "        https://help.sap.com/docs/SAP_HANA_CLIENT\n",
    "    \"\"\"\n",
    "    from urllib.parse import urlparse\n",
    "\n",
    "    parsed = urlparse(url)\n",
    "    return {\n",
    "        \"address\": parsed.hostname,\n",
    "        \"port\": parsed.port or 30015,  # Default: single-tenant, instance 00\n",
    "        \"user\": parsed.username,\n",
    "        \"password\": parsed.password,\n",
    "    }\n",
    "\n",
    "\n",
    "HANA_PARAMS = parse_hana_url(HANA_URL) if HANA_URL else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def measure_performance():\n",
    "    \"\"\"\n",
    "    Context manager to measure time and memory.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    tracemalloc.start()\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    result = {\"rows\": 0}\n",
    "    yield result\n",
    "\n",
    "    elapsed = time.perf_counter() - start_time\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    result[\"elapsed_sec\"] = elapsed\n",
    "    result[\"peak_memory_mb\"] = peak / 1024 / 1024\n",
    "    result[\"rows_per_sec\"] = result[\"rows\"] / elapsed if elapsed > 0 else 0\n",
    "\n",
    "\n",
    "def format_results(name: str, result: dict) -> str:\n",
    "    return (\n",
    "        f\"{name}:\\n\"\n",
    "        f\"  Rows: {result['rows']:,}\\n\"\n",
    "        f\"  Time: {result['elapsed_sec']:.3f}s\\n\"\n",
    "        f\"  Throughput: {result['rows_per_sec']:,.0f} rows/sec\\n\"\n",
    "        f\"  Peak Memory: {result['peak_memory_mb']:.1f} MB\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-1",
   "metadata": {},
   "source": [
    "## Benchmark 1: Fetch to DataFrame\n",
    "\n",
    "Compare fetching query results to a DataFrame (pandas for hdbcli, Polars for pyhdb_rs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "    SELECT\n",
    "        PRODUCT_ID,\n",
    "        PRODUCT_NAME,\n",
    "        PRODUCT_CATEGORY,\n",
    "        NET_PRICE,\n",
    "        STOCK_QTY,\n",
    "        CREATED_AT\n",
    "    FROM BENCHMARK_TABLE\n",
    "    WHERE PRODUCT_ID <= 1000000\n",
    "\"\"\"\n",
    "\n",
    "# pyhdb_rs benchmark\n",
    "with measure_performance() as pyhdb_result, pyhdb_connect(HANA_URL) as conn:\n",
    "    with conn.cursor() as cursor:\n",
    "        df = pl.from_arrow(cursor.execute_arrow(QUERY))\n",
    "        pyhdb_result[\"rows\"] = len(df)\n",
    "\n",
    "print(format_results(\"pyhdb_rs (Polars)\", pyhdb_result))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-1-hdbcli",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_HDBCLI:\n",
    "    # hdbcli benchmark\n",
    "    with measure_performance() as hdbcli_result:\n",
    "        conn = hdbcli.connect(**HANA_PARAMS)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(QUERY)\n",
    "\n",
    "        # Fetch to pandas (hdbcli native way)\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        rows = cursor.fetchall()\n",
    "        df = pd.DataFrame(rows, columns=columns)\n",
    "        hdbcli_result[\"rows\"] = len(df)\n",
    "\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    print(format_results(\"hdbcli (pandas)\", hdbcli_result))\n",
    "\n",
    "    # Calculate speedup\n",
    "    speedup = hdbcli_result[\"elapsed_sec\"] / pyhdb_result[\"elapsed_sec\"]\n",
    "    memory_reduction = hdbcli_result[\"peak_memory_mb\"] / pyhdb_result[\"peak_memory_mb\"]\n",
    "\n",
    "    print(f\"\\n=== pyhdb_rs is {speedup:.1f}x faster ===\")\n",
    "    print(f\"=== pyhdb_rs uses {memory_reduction:.1f}x less memory ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-2",
   "metadata": {},
   "source": [
    "## Benchmark 2: Large Dataset Streaming\n",
    "\n",
    "Compare streaming large datasets that don't fit in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_QUERY = \"SELECT * FROM TRANSACTION_HISTORY\"  # 10M+ rows\n",
    "\n",
    "# pyhdb_rs streaming\n",
    "with measure_performance() as pyhdb_stream, pyhdb_connect(HANA_URL) as conn:\n",
    "    with conn.cursor() as cursor:\n",
    "        reader = cursor.execute_arrow_batches(LARGE_QUERY, batch_size=65536)\n",
    "\n",
    "        total = 0\n",
    "        for batch in reader:\n",
    "            # Simulate processing\n",
    "            total += batch.num_rows\n",
    "\n",
    "        pyhdb_stream[\"rows\"] = total\n",
    "\n",
    "print(format_results(\"pyhdb_rs streaming\", pyhdb_stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-2-hdbcli",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_HDBCLI:\n",
    "    # hdbcli fetchmany (chunked)\n",
    "    with measure_performance() as hdbcli_stream:\n",
    "        conn = hdbcli.connect(**HANA_PARAMS)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(LARGE_QUERY)\n",
    "\n",
    "        total = 0\n",
    "        while True:\n",
    "            rows = cursor.fetchmany(65536)\n",
    "            if not rows:\n",
    "                break\n",
    "            total += len(rows)\n",
    "\n",
    "        hdbcli_stream[\"rows\"] = total\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    print(format_results(\"hdbcli fetchmany\", hdbcli_stream))\n",
    "\n",
    "    speedup = hdbcli_stream[\"elapsed_sec\"] / pyhdb_stream[\"elapsed_sec\"]\n",
    "    print(f\"\\n=== pyhdb_rs streaming is {speedup:.1f}x faster ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-3",
   "metadata": {},
   "source": [
    "## Benchmark 3: Type-Heavy Workload\n",
    "\n",
    "Compare handling of complex types (DECIMAL, TIMESTAMP, LOBs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-3-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "DECIMAL_QUERY = \"\"\"\n",
    "    SELECT\n",
    "        TRANSACTION_ID,\n",
    "        NET_AMOUNT,\n",
    "        TAX_AMOUNT,\n",
    "        DISCOUNT_AMOUNT,\n",
    "        TOTAL_AMOUNT,\n",
    "        EXCHANGE_RATE,\n",
    "        CREATED_AT,\n",
    "        UPDATED_AT\n",
    "    FROM FINANCIAL_TRANSACTIONS\n",
    "    WHERE CREATED_AT >= '2026-01-01'\n",
    "\"\"\"\n",
    "\n",
    "# pyhdb_rs with optimized decimal handling\n",
    "with measure_performance() as pyhdb_decimal, pyhdb_connect(HANA_URL) as conn:\n",
    "    with conn.cursor() as cursor:\n",
    "        df = pl.from_arrow(cursor.execute_arrow(DECIMAL_QUERY))\n",
    "        pyhdb_decimal[\"rows\"] = len(df)\n",
    "\n",
    "print(format_results(\"pyhdb_rs (DECIMAL optimized)\", pyhdb_decimal))\n",
    "print(f\"\\nSchema: {df.schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-4",
   "metadata": {},
   "source": [
    "## Benchmark 4: Concurrent Connections\n",
    "\n",
    "Compare performance under concurrent load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-4-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "CONCURRENT_QUERY = \"SELECT * FROM SALES_ORDERS WHERE ORDER_ID <= 10000\"\n",
    "NUM_THREADS = 8\n",
    "ITERATIONS = 10\n",
    "\n",
    "\n",
    "def pyhdb_worker(iteration: int) -> int:\n",
    "    with pyhdb_connect(HANA_URL) as conn, conn.cursor() as cursor:\n",
    "        df = pl.from_arrow(cursor.execute_arrow(CONCURRENT_QUERY))\n",
    "        return len(df)\n",
    "\n",
    "\n",
    "# pyhdb_rs concurrent benchmark\n",
    "with measure_performance() as pyhdb_concurrent:\n",
    "    with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n",
    "        futures = [executor.submit(pyhdb_worker, i) for i in range(ITERATIONS)]\n",
    "        total = sum(f.result() for f in as_completed(futures))\n",
    "\n",
    "    pyhdb_concurrent[\"rows\"] = total\n",
    "\n",
    "print(f\"Concurrent test: {NUM_THREADS} threads, {ITERATIONS} iterations\")\n",
    "print(format_results(\"pyhdb_rs concurrent\", pyhdb_concurrent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## pyhdb_rs Performance Summary\n",
    "\n",
    "1. **Zero-copy Arrow transfer**\n",
    "   - Data stays in Arrow format from Rust to Polars\n",
    "   - No Python object creation per cell\n",
    "   - No serialization/deserialization overhead\n",
    "\n",
    "2. **Rust protocol implementation**\n",
    "   - HANA protocol parsing in native code\n",
    "   - No GIL contention during network I/O\n",
    "   - SIMD-optimized data processing\n",
    "\n",
    "3. **Columnar memory layout**\n",
    "   - Arrow's columnar format is cache-friendly\n",
    "   - Better memory locality for analytics\n",
    "   - Efficient compression and encoding\n",
    "\n",
    "4. **Optimized type conversions**\n",
    "   - Direct BigInt arithmetic for DECIMAL (no string parsing)\n",
    "   - Thread-local Python type caches\n",
    "   - Builder reuse at batch boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary = pl.DataFrame(\n",
    "    {\n",
    "        \"Benchmark\": [\n",
    "            \"DataFrame fetch (1M rows)\",\n",
    "            \"Streaming (10M rows)\",\n",
    "            \"DECIMAL processing\",\n",
    "            \"Concurrent (8 threads)\",\n",
    "        ],\n",
    "        \"pyhdb_rs (sec)\": [\n",
    "            pyhdb_result.get(\"elapsed_sec\", 0),\n",
    "            pyhdb_stream.get(\"elapsed_sec\", 0),\n",
    "            pyhdb_decimal.get(\"elapsed_sec\", 0),\n",
    "            pyhdb_concurrent.get(\"elapsed_sec\", 0),\n",
    "        ],\n",
    "        \"pyhdb_rs Memory (MB)\": [\n",
    "            pyhdb_result.get(\"peak_memory_mb\", 0),\n",
    "            pyhdb_stream.get(\"peak_memory_mb\", 0),\n",
    "            pyhdb_decimal.get(\"peak_memory_mb\", 0),\n",
    "            pyhdb_concurrent.get(\"peak_memory_mb\", 0),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"=== Performance Summary ===\")\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhdb-rs (.venv)",
   "language": "python",
   "name": "pyhdb-rs"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
